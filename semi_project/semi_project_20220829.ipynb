{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 1,
>>>>>>> 75916823a4373d44c36119f563a184d834ce5312
   "id": "d0cc66d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "\n",
    "def draw_ball_location(img_color, locations):\n",
    "    for i in range(len(locations)-1):\n",
    "\n",
    "        if locations[0] is None or locations[1] is None:\n",
    "            continue\n",
    "\n",
    "        cv2.line(img_color, tuple(locations[i]), tuple(locations[i+1]), (0, 255, 255), 3)\n",
    "\n",
    "    return img_color\n",
    "\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print('camera open failed')\n",
    "    sys.exit()\n",
    "\n",
    "list_ball_location = []\n",
    "history_ball_locations = []\n",
    "isDraw = True\n",
    "\n",
    "while True:\n",
    "\n",
    "    ret,img_color = cap.read()\n",
    "\n",
    "    img_color = cv2.flip(img_color, 1)\n",
    "\n",
    "\n",
    "    img_hsv = cv2.cvtColor(img_color, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    hue_blue = 120\n",
    "    lower_blue = (hue_blue-20, 150, 0)\n",
    "    upper_blue = (hue_blue+20, 255, 255)\n",
    "    img_mask = cv2.inRange(img_hsv, lower_blue, upper_blue)\n",
    "\n",
    "    kernel = cv2.getStructuringElement( cv2.MORPH_RECT, ( 5, 5 ) )\n",
    "    img_mask = cv2.morphologyEx(img_mask, cv2.MORPH_DILATE, kernel, iterations = 3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    nlabels, labels, stats, centroids = cv2.connectedComponentsWithStats(img_mask)\n",
    "\n",
    "\n",
    "\n",
    "    max = -1\n",
    "    max_index = -1 \n",
    "\n",
    "    for i in range(nlabels):\n",
    " \n",
    "        if i < 1:\n",
    "            continue\n",
    "\n",
    "        area = stats[i, cv2.CC_STAT_AREA]\n",
    "\n",
    "        if area > max:\n",
    "            max = area\n",
    "            max_index = i\n",
    "\n",
    "\n",
    "    if max_index != -1:\n",
    "\n",
    "\n",
    "        center_x = int(centroids[max_index, 0])\n",
    "        center_y = int(centroids[max_index, 1]) \n",
    "        left = stats[max_index, cv2.CC_STAT_LEFT]\n",
    "        top = stats[max_index, cv2.CC_STAT_TOP]\n",
    "        width = stats[max_index, cv2.CC_STAT_WIDTH]\n",
    "        height = stats[max_index, cv2.CC_STAT_HEIGHT]\n",
    "\n",
    "\n",
    "        cv2.rectangle(img_color, (left, top), (left + width, top + height), (0, 0, 255), 5)\n",
    "        cv2.circle(img_color, (center_x, center_y), 10, (0, 255, 0), -1)\n",
    "\n",
    "        if isDraw:\n",
    "            list_ball_location.append((center_x, center_y))\n",
    "        \n",
    "        else:\n",
    "            history_ball_locations.append(list_ball_location.copy())\n",
    "            list_ball_location.clear()\n",
    "\n",
    "\n",
    "    img_color = draw_ball_location(img_color, list_ball_location)\n",
    "\n",
    "    for ball_locations in history_ball_locations:\n",
    "        img_color = draw_ball_location(img_color, ball_locations)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    cv2.imshow('Blue', img_mask)\n",
    "    cv2.imshow('Result', img_color)\n",
    "    \n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27: # esc\n",
    "        break\n",
    "    elif key == 32: # space bar\n",
    "        list_ball_location.clear()\n",
    "        history_ball_locations.clear()\n",
    "    elif key == ord('v'):\n",
    "        isDraw = not isDraw\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
   "id": "d0077c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f962ebe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print('camera open failed')\n",
    "    sys.exit()\n",
    "    \n",
    "w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS)*0.8)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "    \n",
    "# out = cv2.VideoWriter('output.avi', fourcc,fps, (w,h)) \n",
    "   \n",
    "srcR = cv2.imread('./samples/640x480-blizzard-blue-solid-color-background.jpg')\n",
    "srcL = cv2.imread('./samples/640x480-dark-gray-solid-color-background.jpg')\n",
    "srcU = cv2.imread('./samples/640x480-dark-pastel-purple-solid-color-background.jpg')\n",
    "srcD = cv2.imread('./samples/640x480-deep-sky-blue-solid-color-background.jpg')\n",
    "dst = cv2.imread('./samples/640x480-magnolia-solid-color-background.jpg')\n",
    "\n",
    "cv2.namedWindow('dst', cv2.WINDOW_NORMAL)\n",
    "cv2.setWindowProperty('dst', cv2.WND_PROP_FULLSCREEN,\n",
    "         cv2.WINDOW_FULLSCREEN)\n",
    "\n",
    "while True:    \n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    model = './opencv_face_detector_uint8.pb'\n",
    "    config = './opencv_face_detector.pbtxt.txt'\n",
    "    face_net = cv2.dnn.readNet(model, config)\n",
    "\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1, (300, 300), (104, 177, 123), swapRB = False)\n",
    "    face_net.setInput(blob)\n",
    "    out = face_net.forward()\n",
    "\n",
    "    detect = out[0, 0, :, :]\n",
    "\n",
    "\n",
    "    for i in range(detect.shape[0]):\n",
    "        confidence = detect[i, 2]\n",
    "\n",
    "        if confidence > 0.5:\n",
    "\n",
    "            x1 = int(detect[i, 3]*w)\n",
    "            y1 = int(detect[i, 4]*h)\n",
    "            x2 = int(detect[i, 5]*w)\n",
    "            y2 = int(detect[i, 6]*h)\n",
    "            \n",
    "            center_boxx = ((x2-x1)//2)+x1\n",
    "            center_boxy = ((y2-y1)//2)+y1\n",
    "            centerx = w//2\n",
    "            centery = h//2\n",
    "\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "            text = 'Face: {}%'.format(round(confidence*100, 2))\n",
    "            cv2.putText(frame, text, (x1, y1-1), cv2.FONT_HERSHEY_COMPLEX,\n",
    "                       1, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "            if x1 == x1+1:\n",
    "                cv2.imshow('image', img)\n",
    "            \n",
    "            if center_boxx <= centerx and center_boxy <= centery:\n",
    "                l = abs(centerx - center_boxx)\n",
    "                d = abs(center_boxy - centery)\n",
    "            if center_boxx >= centerx and center_boxy <= centery:\n",
    "                r = abs(center_boxx -centerx)\n",
    "                d = abs(center_boxy - centery)\n",
    "            if center_boxx <= centerx and center_boxy >= centery:\n",
    "                l = abs(centerx - center_boxx)\n",
    "                u = abs(centery - center_boxy)\n",
    "            if center_boxx >= centerx and center_boxy >= centery:\n",
    "                r = abs(center_boxx -centerx)\n",
    "                u = abs(centery - center_boxy)\n",
    "\n",
    "\n",
    "            ptsL1 = np.float32([[0,0], [0,480], [640, 0], [640,480]])\n",
    "            ptsL2 = np.float32([[0,0], [0,480], [200+(l*(-1))+(r*1), 180+(u*(-1))+(d*1)], \n",
    "                                [200+(l*(-1))+(r*1),300+(u*(-1))+(d*1)]])\n",
    "\n",
    "            ptsR1 = np.float32([[0,0], [0,480], [640, 0], [640,480]])\n",
    "            ptsR2 = np.float32([[440+(l*(-1))+(r*1),180+(u*(-1))+(d*1)], \n",
    "                                [440+(l*(-1))+(r*1),300+(u*(-1))+(d*1)], [640, 0], [640,480]])\n",
    "\n",
    "            ptsU1 = np.float32([[0,0], [0,480], [640, 0], [640,480]])\n",
    "            ptsU2 = np.float32([[0,0], [200+(l*(-1))+(r*1),180+(u*(-1))+(d*1)], \n",
    "                                [640, 0], [440+(l*(-1))+(r*1),180+(u*(-1))+(d*1)]])\n",
    "\n",
    "            ptsD1 = np.float32([[0,0], [0,480], [640, 0], [640,480]])\n",
    "            ptsD2 = np.float32([[200+(l*(-1))+(r*1),300+(u*(-1))+(d*1)], [0,480], \n",
    "                                [440+(l*(-1))+(r*1), 300+(u*(-1))+(d*1)], [640,480]])\n",
    "\n",
    "            mtrxR = cv2.getPerspectiveTransform(ptsR1, ptsR2)\n",
    "            mtrxL = cv2.getPerspectiveTransform(ptsL1, ptsL2)\n",
    "            mtrxU = cv2.getPerspectiveTransform(ptsU1, ptsU2)\n",
    "            mtrxD = cv2.getPerspectiveTransform(ptsD1, ptsD2)\n",
    "\n",
    "            srcR1 = cv2.warpPerspective(srcR, mtrxR, (640, 480))\n",
    "            srcL1 = cv2.warpPerspective(srcL, mtrxL, (640, 480))\n",
    "            srcU1 = cv2.warpPerspective(srcU, mtrxU, (640, 480))\n",
    "            srcD1 = cv2.warpPerspective(srcD, mtrxD, (640, 480))\n",
    "\n",
    "            maskR = cv2.inRange(srcR1, (0, 0, 50), (255, 255, 255))\n",
    "            maskL = cv2.inRange(srcL1, (0, 50, 50), (255, 255, 255))\n",
    "            maskU = cv2.inRange(srcU1, (50, 0, 50), (255, 255, 255))\n",
    "            maskD = cv2.inRange(srcD1, (50, 50, 0), (255, 255, 255))\n",
    "\n",
    "            k = cv2.getStructuringElement(cv2.MORPH_CROSS, (3,3))\n",
    "\n",
    "            maskR = cv2.erode(maskR, k)\n",
    "            maskR = cv2.dilate(maskR, k)\n",
    "\n",
    "            maskL = cv2.erode(maskL, k)\n",
    "            maskL = cv2.dilate(maskL, k)\n",
    "\n",
    "            maskU = cv2.erode(maskU, k)\n",
    "            maskU = cv2.dilate(maskU, k)\n",
    "\n",
    "            maskD = cv2.erode(maskD, k)\n",
    "            maskD = cv2.dilate(maskD, k)    \n",
    "\n",
    "            dst1 = dst.copy()\n",
    "\n",
    "\n",
    "            cv2.copyTo(srcR1, maskR, dst1)\n",
    "            cv2.copyTo(srcL1, maskL, dst1)\n",
    "            cv2.copyTo(srcU1, maskU, dst1)\n",
    "            cv2.copyTo(srcD1, maskD, dst1)     \n",
    "\n",
    "            cv2.imshow('dst', dst1)\n",
    "\n",
    "            \n",
    "#             cv2.circle(frame, (((x2-x1)//2)+x1,((y2-y1)//2)+y1), 10, (255,0,0), -1)\n",
    "                    \n",
    "    \n",
    "    if not ret:\n",
    "        print('frame open failed')\n",
    "        break\n",
    "    \n",
    "\n",
    "    \n",
    "    cv2.imshow('image', frame)\n",
    "    \n",
    "    if cv2.waitKey(20) == 27:\n",
    "        break\n",
    "\n",
    "\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05fdfabd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "print(abs(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24db3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread('./catC.bmp')\n",
    "img2 = cv2.imread('./catD.bmp')\n",
    "img3 = cv2.imread('./catL.bmp')\n",
    "img4 = cv2.imread('./catR.bmp')\n",
    "img5 = cv2.imread('./catU.bmp')\n",
    "\n",
    "add_img1 = img1 + img2 \n",
    "add_img2 = cv2.add(img1, img2)\n",
    "\n",
    "add_img3 = img3 + img4 + img5\n",
    "add_img4 = cv2.add(img3, img4, img5)\n",
    "\n",
    "add_img5 = add_img1 + add_img3\n",
    "add_img6 = cv2.add(add_img2, add_img4)\n",
    "\n",
    "cv2.imshow('img1+img2', add_img5)\n",
    "#     cv2.imshow('add(img1, img2)', add_img6)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2884dc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def call_track(pos):\n",
    "    lux = cv2.getTrackbarPos('LU_x', 'dst')\n",
    "    luy = cv2.getTrackbarPos('LU_y', 'dst')\n",
    "    rux = cv2.getTrackbarPos('RU_x', 'dst')\n",
    "    ruy = cv2.getTrackbarPos('RU_y', 'dst')\n",
    "    ldx = cv2.getTrackbarPos('LD_x', 'dst')\n",
    "    ldy = cv2.getTrackbarPos('LD_y', 'dst')\n",
    "    rdx = cv2.getTrackbarPos('RD_x', 'dst')\n",
    "    rdy = cv2.getTrackbarPos('RD_y', 'dst')\n",
    "    \n",
    "    pts1 = np.float32([[0,0], [0,rows], [cols, 0], [cols,rows]])\n",
    "    pts2 = np.float32([[lux,luy], [ldx, ldy], [rux, ruy], [rdx, rdy]])\n",
    "    mtrx = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "    dst = cv2.warpPerspective(add_img5, mtrx, (cols, rows))\n",
    "    dst1 = dst.copy()\n",
    "    cv2.imshow('dst1', dst1)\n",
    "\n",
    "img1 = cv2.imread('./catC.bmp')\n",
    "img2 = cv2.imread('./catD.bmp')\n",
    "img3 = cv2.imread('./catL.bmp')\n",
    "img4 = cv2.imread('./catR.bmp')\n",
    "img5 = cv2.imread('./catU.bmp')\n",
    "\n",
    "add_img1 = img1 + img2 \n",
    "add_img2 = cv2.add(img1, img2)\n",
    "\n",
    "add_img3 = img3 + img4 + img5\n",
    "add_img4 = cv2.add(img3, img4, img5)\n",
    "\n",
    "add_img5 = add_img1 + add_img3\n",
    "add_img6 = cv2.add(add_img2, add_img4)\n",
    "\n",
    "cv2.imshow('img1+img2', add_img5)\n",
    "rows, cols = add_img5.shape[:2]\n",
    "\n",
    "cv2.circle(img1, (0,0), 10, (255,0,0), -1)\n",
    "cv2.circle(img1, (0,rows), 10, (0,255,0), -1)\n",
    "cv2.circle(img1, (cols,0), 10, (0,0,255), -1)\n",
    "cv2.circle(img1, (cols,rows), 10, (0,255,255), -1)\n",
    "\n",
    "    \n",
    "cv2.namedWindow('dst')\n",
    "cv2.createTrackbar('LU_x', 'dst', 0, 480, call_track)\n",
    "cv2.createTrackbar('LU_y', 'dst', 0, 640, call_track)\n",
    "cv2.createTrackbar('LD_x', 'dst', 0, 480, call_track)\n",
    "cv2.createTrackbar('LD_y', 'dst', 480, 480, call_track)\n",
    "cv2.createTrackbar('RU_x', 'dst', 640, 640, call_track)\n",
    "cv2.createTrackbar('RU_y', 'dst', 0, 480, call_track)\n",
    "cv2.createTrackbar('RD_x', 'dst', 640, 640, call_track)\n",
    "cv2.createTrackbar('RD_y', 'dst', 480, 480, call_track)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3667232",
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 2,
   "id": "d0077c27",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mediapipe'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m mp_drawing \u001b[38;5;241m=\u001b[39m mp\u001b[38;5;241m.\u001b[39msolutions\u001b[38;5;241m.\u001b[39mdrawing_utils\n\u001b[0;32m      4\u001b[0m mp_drawing_styles \u001b[38;5;241m=\u001b[39m mp\u001b[38;5;241m.\u001b[39msolutions\u001b[38;5;241m.\u001b[39mdrawing_styles\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mediapipe'"
     ]
    }
   ],
>>>>>>> 75916823a4373d44c36119f563a184d834ce5312
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "039e0680",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ce269c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addImage(imgfile1, imgfile2, imgfile3, imgfile4, imgfile5):\n",
    "    img1 = cv2.imread(imgfile1)\n",
    "    img2 = cv2.imread(imgfile2)\n",
    "    img3 = cv2.imread(imgfile3)\n",
    "    img4 = cv2.imread(imgfile4)\n",
    "    img5 = cv2.imread(imgfile5)\n",
    "        \n",
    "    add_img1 = img1 + img2 \n",
    "    add_img2 = cv2.add(img1, img2)\n",
    "    \n",
    "    add_img3 = img3 + img4 + img5\n",
    "    add_img4 = cv2.add(img3, img4, img5)\n",
    "    \n",
    "    add_img5 = add_img1 + add_img3\n",
    "    add_img6 = cv2.add(add_img2, add_img4)\n",
    "    \n",
    "    cv2.imshow('img1+img2', add_img5)\n",
    "#     cv2.imshow('add(img1, img2)', add_img6)\n",
    "    \n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "\n",
    "\n",
    "addImage('./catC.bmp', './catD.bmp', \n",
    "         './catL.bmp', './catR.bmp', './catU.bmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9e9151",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95f4e04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdcd0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "center = w//2, h//2\n",
    "center_box = (w-((w-x2)+x1))*0.5, (h-((h-y2)+y1))*0.5\n",
    "while True:\n",
    "    if center_box == center:\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b959e25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebadab0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a521d5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "def bar(x):\n",
    "    \"\"\" Print the value of the trackbar whenever it changes \"\"\"\n",
    "    print(f\"value: {x}\")\n",
    "\n",
    "\n",
    "img = cv2.imread(\"./cat.bmp\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "thresholdSteps = 10\n",
    "beginningTrackbarValue = 3  # Used in the call to createTrackbar to set the initial trackbar value\n",
    "cv2.namedWindow(\"Image\")\n",
    "cv2.createTrackbar(\"trackbar1\", \"Image\", beginningTrackbarValue, thresholdSteps, bar)\n",
    "\n",
    "previousTrackbarValue = -1  # Set this to -1 so the threshold will be applied and the image displayed the first time through the loop\n",
    "while True:\n",
    "    newTrackBarValue = cv2.getTrackbarPos(\"trackbar1\", \"Image\")\n",
    "    # Don't process the image if the trackbar value is still the same\n",
    "    if newTrackBarValue != previousTrackbarValue:\n",
    "        thresholdValue = newTrackBarValue * 255 / thresholdSteps\n",
    "        print(f\"threshold value: {thresholdValue}\")\n",
    "        _, threshImg = cv2.threshold(img, thresholdValue, 255, cv2.THRESH_BINARY)\n",
    "        cv2.imshow(\"Image\", threshImg)\n",
    "        previousTrackbarValue = newTrackBarValue\n",
    "    key = cv2.waitKey(10)\n",
    "    if key == 27:\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4e87c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "top_left_corner=[]\n",
    "bottom_right_corner=[]\n",
    "def drawRectangle(action, x, y, flags, *userdata):\n",
    "    \n",
    "  global top_left_corner, bottom_right_corner\n",
    "  if action == cv2.EVENT_LBUTTONDOWN:\n",
    "    top_left_corner = [(x,y)]\n",
    "  elif action == cv2.EVENT_LBUTTONUP:\n",
    "    bottom_right_corner = [(x,y)]   \n",
    "    cv2.rectangle(image, top_left_corner[0], bottom_right_corner[0], (0,255,0),2, 8)\n",
    "    cv2.imshow(\"Window\",image)\n",
    "image = cv2.imread(\"./cat.bmp\")\n",
    "temp = image.copy()\n",
    "cv2.namedWindow(\"Window\")\n",
    "\n",
    "cv2.setMouseCallback(\"Window\", drawRectangle)\n",
    "k=0\n",
    "while k!=113:\n",
    "  cv2.imshow(\"Window\", image)\n",
    "  k = cv2.waitKey(0)\n",
    "  if (k == 99):\n",
    "    image= temp.copy()\n",
    "    cv2.imshow(\"Window\", image)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce151fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab9654c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "cv2.namedWindow('Face')\n",
    "face_cascade = cv2.CascadeClassifier()\n",
    "face_cascade.load('./haarcascade_frontalface_default.xml')\n",
    "\n",
    "def call_track(pos):\n",
    "    lux = cv2.getTrackbarPos('LU_x', 'dst')\n",
    "    luy = cv2.getTrackbarPos('LU_y', 'dst')\n",
    "    rux = cv2.getTrackbarPos('RU_x', 'dst')\n",
    "    ruy = cv2.getTrackbarPos('RU_y', 'dst')\n",
    "    ldx = cv2.getTrackbarPos('LD_x', 'dst')\n",
    "    ldy = cv2.getTrackbarPos('LD_y', 'dst')\n",
    "    rdx = cv2.getTrackbarPos('RD_x', 'dst')\n",
    "    rdy = cv2.getTrackbarPos('RD_y', 'dst')\n",
    "\n",
    "    pts1 = np.float32([[0,0], [0,rows], [cols, 0], [cols,rows]])\n",
    "    pts2 = np.float32([[lux,luy], [ldx, ldy], [rux, ruy], [rdx, rdy]])\n",
    "    mtrx = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "    dst = cv2.warpPerspective(img, mtrx, (cols, rows))\n",
    "    dst1 = dst.copy()\n",
    "    cv2.imshow('dst1', dst1)\n",
    "\n",
    "img = cv2.imread('./cat.bmp')\n",
    "rows, cols = img.shape[:2]\n",
    "\n",
    "cv2.createTrackbar('BoxW', 'Face', 30, 255, nothing)\n",
    "cv2.createTrackbar('BoxH', 'Face', 30, 255, nothing)\n",
    "\n",
    "while True:\n",
    "    \n",
    "    boxW = cv2.getTrackbarPos('BoxW', 'Face')\n",
    "    boxH = cv2.getTrackbarPos('BoxH', 'Face')\n",
    "    #read the camera image\n",
    "    #카메라에서 이미지 얻기\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    grayframe = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    grayframe = cv2.equalizeHist(grayframe)\n",
    "    \n",
    "        # trackbar를 통해 받은 변수 boxW와 boxH를 적용함.\n",
    "    faces = face_cascade.detectMultiScale(grayframe, 1.1, 3, 0, (boxW, boxH))\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),3, 4, 0)\n",
    "\n",
    "\n",
    "    cv2.imshow('Face',frame)\n",
    "\n",
    "    #wait keyboard input until 10ms\n",
    "    #10ms 동안 키입력 대기\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break;\n",
    "        \n",
    "cv2.namedWindow('dst')\n",
    "cv2.createTrackbar('LU_x', 'dst', 0, 480, call_track)\n",
    "cv2.createTrackbar('LU_y', 'dst', 0, 640, call_track)\n",
    "cv2.createTrackbar('LD_x', 'dst', 0, 480, call_track)\n",
    "cv2.createTrackbar('LD_y', 'dst', 480, 480, call_track)\n",
    "cv2.createTrackbar('RU_x', 'dst', 640, 640, call_track)\n",
    "cv2.createTrackbar('RU_y', 'dst', 0, 480, call_track)\n",
    "cv2.createTrackbar('RD_x', 'dst', 640, 640, call_track)\n",
    "cv2.createTrackbar('RD_y', 'dst', 480, 480, call_track)\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daff1fb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c66fcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1e92ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a7a112",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "CAM_ID = 0\n",
    "\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "cap = cv2.VideoCapture(CAM_ID) #카메라 생성\n",
    "\n",
    "if cap.isOpened() == False: #카메라 생성 확인\n",
    "    print ('Can\\'t open the CAM(%d)' % (CAM_ID))\n",
    "    exit()\n",
    "\n",
    "cv2.namedWindow('Face')\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier()\n",
    "face_cascade.load('./haarcascade_frontalface_default.xml')\n",
    "\n",
    "cv2.createTrackbar('BoxW', 'Face', 30, 255, nothing)\n",
    "cv2.createTrackbar('BoxH', 'Face', 30, 255, nothing)\n",
    "\n",
    "while(True):\n",
    "\n",
    "    boxW = cv2.getTrackbarPos('BoxW', 'Face')\n",
    "    boxH = cv2.getTrackbarPos('BoxH', 'Face')\n",
    "    #read the camera image\n",
    "    #카메라에서 이미지 얻기\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    grayframe = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    grayframe = cv2.equalizeHist(grayframe)\n",
    "\n",
    "\n",
    "    # trackbar를 통해 받은 변수 boxW와 boxH를 적용함.\n",
    "    faces = face_cascade.detectMultiScale(grayframe, 1.1, 3, 0, (boxW, boxH))\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),3, 4, 0)\n",
    "\n",
    "\n",
    "    cv2.imshow('Face',frame)\n",
    "\n",
    "    #wait keyboard input until 10ms\n",
    "    #10ms 동안 키입력 대기\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break;\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyWindow('Face')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9139c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def call_track(pos):\n",
    "    lux = cv2.getTrackbarPos('LU_x', 'dst')\n",
    "    luy = cv2.getTrackbarPos('LU_y', 'dst')\n",
    "    rux = cv2.getTrackbarPos('RU_x', 'dst')\n",
    "    ruy = cv2.getTrackbarPos('RU_y', 'dst')\n",
    "    ldx = cv2.getTrackbarPos('LD_x', 'dst')\n",
    "    ldy = cv2.getTrackbarPos('LD_y', 'dst')\n",
    "    rdx = cv2.getTrackbarPos('RD_x', 'dst')\n",
    "    rdy = cv2.getTrackbarPos('RD_y', 'dst')\n",
    "    \n",
    "    pts1 = np.float32([[0,0], [0,rows], [cols, 0], [cols,rows]])\n",
    "    pts2 = np.float32([[lux,luy], [ldx, ldy], [rux, ruy], [rdx, rdy]])\n",
    "    mtrx = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "    dst = cv2.warpPerspective(img, mtrx, (cols, rows))\n",
    "    dst1 = dst.copy()\n",
    "    cv2.imshow('dst1', dst1)\n",
    "\n",
    "img = cv2.imread('../open_cv/fig/cat.bmp')\n",
    "rows, cols = img.shape[:2]\n",
    "\n",
    "\n",
    "# cv2.circle(img, (0,0), 10, (255,0,0), -1)\n",
    "# cv2.circle(img, (0,rows), 10, (0,255,0), -1)\n",
    "# cv2.circle(img, (cols,0), 10, (0,0,255), -1)\n",
    "# cv2.circle(img, (cols,rows), 10, (0,255,255), -1)\n",
    "\n",
    "    \n",
    "cv2.namedWindow('dst')\n",
    "cv2.createTrackbar('LU_x', 'dst', 0, 480, call_track)\n",
    "cv2.createTrackbar('LU_y', 'dst', 0, 640, call_track)\n",
    "cv2.createTrackbar('LD_x', 'dst', 0, 480, call_track)\n",
    "cv2.createTrackbar('LD_y', 'dst', 480, 480, call_track)\n",
    "cv2.createTrackbar('RU_x', 'dst', 640, 640, call_track)\n",
    "cv2.createTrackbar('RU_y', 'dst', 0, 480, call_track)\n",
    "cv2.createTrackbar('RD_x', 'dst', 640, 640, call_track)\n",
    "cv2.createTrackbar('RD_y', 'dst', 480, 480, call_track)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1406e2f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1856a20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2364f8bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784f4d75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5f21f7",
=======
   "id": "4f35223f",
>>>>>>> 75916823a4373d44c36119f563a184d834ce5312
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
